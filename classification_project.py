# -*- coding: utf-8 -*-
"""Classification_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fnK8WD4zusZ5wtmu88A1wINA7G_W1p3C

**Problem statement**
To ascertain the best classification model which would predict the likelihood of a passenger recommending the airline he is preferring for journey to his /her mates based on the passenger service experience
"""

import pandas as pd
import numpy as np

df=pd.read_excel('/content/drive/MyDrive/data_airline_reviews.xlsx')

df.dropna(inplace=True) # droping null values
df

"""**EDA for Cabin Composition**"""

class_plt=pd.DataFrame(df.groupby(by='traveller_type')['cabin'].value_counts())
class_plt.rename(columns={'cabin':'count_class'},inplace=True)
import seaborn as sns
class__plt=class_plt.reset_index()
class__plt.groupby(by='traveller_type')
class__plt
sns.barplot(data=class__plt,x='traveller_type',y='count_class',hue='cabin')

"""**EDA for recommendation or not recommendation based on class and Cabin Service**"""

plt_cbn=sns.boxplot(data=df,x='cabin',y='cabin_service', hue = df['recommended'], palette= ['orange','purple']) #ploting boxplot
plt_cbn.legend(loc=1) # Moving legend to right of the graph



"""***Labeling Data in Recommended column***"""

df['recommended'].replace({'yes':1,'no':0},inplace=True) # replacing yes=1 and no=0

df

"""**EDA to ascertain top 5 and bottom 5 Airlines in the data**"""

import seaborn as sns # importing seaborn
import matplotlib.pyplot as plt # importing matplotlib

y_=pd.DataFrame(df['airline'].value_counts().nlargest(n=5)) # creating a new dataframe
 y_.reset_index(names='Airline',inplace=True) # reseting index
 y_.rename(columns={'airline':'Count_of_airlines'},inplace=True) # renaming airline column
 plt=sns.barplot(data=y_,x='Airline',y='Count_of_airlines',width=0.5,orient='v') # ploting bar plot
 plt.set_xticklabels(labels=y_['Airline'],rotation=90,verticalalignment='center_baseline') # verticle movement of x ticks labels
 for i in plt.containers:
    plt.bar_label(i) # labeling the actual values of count_of_airlines on top of bars

y__=pd.DataFrame(df['airline'].value_counts().nsmallest(n=5))
 y__.reset_index(names='Airline',inplace=True)
 y__.rename(columns={'airline':'Count_of_airlines'},inplace=True)
 plt_=sns.barplot(data=y__,x='Airline',y='Count_of_airlines',width=0.5,orient='v')
 plt_.set_xticklabels(labels=y__['Airline'],rotation=90,verticalalignment='center_baseline')
 for i in plt_.containers:
    plt_.bar_label(i)

"""**EDA for finding a Airline with best tradeoff between "In Air service" and "Ground Service"**"""

eda1_df=pd.DataFrame(df[['airline','seat_comfort','cabin_service','food_bev','entertainment','ground_service']]) # creating a new dataframe
eda2_df=pd.DataFrame(eda1_df.groupby(by='airline')['seat_comfort','cabin_service','food_bev','entertainment','ground_service'].mean()) # grouping by airline and aggregating other columns by mean
eda2_df['Avg_cabin_comft']=eda2_df[['seat_comfort','cabin_service','food_bev','entertainment']].mean(axis=1) # creating a new column
eda3_df=eda2_df.nlargest(columns=['Avg_cabin_comft'],n=10) # n largest values using Avg_cabin_comft column
eda3_df.reset_index(inplace=True) # reseting the index
sctrplt=sns.scatterplot(data=eda3_df,x='airline',y='Avg_cabin_comft',size='ground_service') # ploting a scatterplot
sctrplt.set_xticklabels(labels=eda3_df['airline'],rotation=90,verticalalignment='center_baseline') # Aligning the x labels vertically

df.drop(columns=['review_date',	'customer_review',	'aircraft', 'traveller_type', 'cabin',	'route','date_flown'],inplace=True) # droping irrelevant columns for the models

crr=df.corr() # correlation of dataframe df
sns.heatmap(crr,annot=True) # ploting heatmap

df.drop(columns='overall',inplace=True) # removing "overall" column to avoid multicolinearity taking threshold as 0.8 in the heatmap

df

"""**Checking Class Imbalance**"""

sns.displot(df['recommended']) # class imbalance is there

df['recommended'].value_counts()  # Almost 50% class imbalance

"""**Random Oversampling to balance the class imbalance**"""

from imblearn.over_sampling import RandomOverSampler # importing Randomoversampler
ros=RandomOverSampler(sampling_strategy=1) # Random over sampling using the minority class
ros_x,ros_y=ros.fit_resample(x,y) # fitting the resampling

ros_y.value_counts().plot.pie(autopct="%0.2f") # ploting the piechart

"""**Test Train Split with Training= 75% of Data and Testing= 25% of** **Data**"""

from sklearn.model_selection import train_test_split # importing test train split
x=df.drop(columns=['recommended','airline','author'])
y=df['recommended']
x_train,x_test,y_train,y_test= train_test_split(ros_x,ros_y,test_size=0.25) # spliting test train data in 25% and 75% respectively

"""**Logistic** **Regression**"""

from sklearn.linear_model import LogisticRegression # importing Logistic Regression
lg_reg= LogisticRegression()
lg_reg.fit(x_train,y_train) # fitting the logistic regression

y_predict=lg_reg.predict(x_test) # calling the prediction function

from sklearn.metrics import classification_report ,confusion_matrix # importing confusion matrix and classification report for checking model accuracy

report_lR = classification_report(y_test, y_predict) # classification report
print(report_lR)

conf_mat= confusion_matrix(y_test,y_predict) # creating the confusion matrix
print(conf_mat)

sns.heatmap(conf_mat,annot=True,fmt='0.2f') # ploting heatmap of the confusion matrix

"""Decision Tree

"""

from sklearn.tree import DecisionTreeClassifier # importing decision tree classifier

dt= DecisionTreeClassifier() # creating the decision tree object
dt.fit(x_train,y_train) # fitting the decision tree

y__pred= dt.predict(x_test) # prediction on test data

report_dt = classification_report(y_test, y__pred) # classification report
print(report_dt)

conf_mat= confusion_matrix(y_test,y__pred) # confusion matrix
print(conf_mat)

"""**Hyperparameter** **Tuning**"""

from sklearn.model_selection import GridSearchCV # importing GridSearchCV for hyperparameter tuning of decision tree model

parameters= {"criterion":["gini","entropy",'loss_log'],"max_depth":[7,8,9],"min_samples_split":[1,2,3],"min_samples_leaf":[1,2,3]} # creating dictionary of parameters
scoring_=['f1','recall','precision','accuracy'] # scoring methods for gridsearch

dt_gscv=GridSearchCV(estimator=dt,param_grid=parameters,scoring=scoring_,refit='accuracy',cv=2) # creating a gridsearchcv object

dt_gscv.fit(x_train,y_train) # fitting the gridsearchcv decision tree model

dt_gscv.best_params_ # getting the best parameters

dt_gscv.best_score_ # getting the score

"""**RANDOM** **fOREST**"""

from sklearn.ensemble import RandomForestClassifier # importing Rnadom forest classifier

randf= RandomForestClassifier() # creating Randomforest classifier object
randf.fit(x_train,y_train) # fitting the random forest model

rand_predict__=randf.predict(x_test) # prediction

report_ran_forest = classification_report(y_test, rand_predict__) # classification report of the model
print(report_ran_forest)

"""**Hyperparameter** **Tuning**"""

randf_gridcv = GridSearchCV(estimator=randf,
                       param_grid = parameters,
                       cv =   2, verbose=2) # creating random forest gridsearchcv object

randf_gridcv.fit(x_train,y_train) # fitting the random forest gridsearchcv

randf_gridcv.best_params_ # getting the best parameters

randf_gridcv.best_score_ # getting the best score of the model

"""**SVM**"""

from sklearn.svm import SVC # importing support vector classification
scv__=SVC(kernel='linear') # creating the svc object

scv__.fit(x_train,y_train) # fitting the model

svc_pred=scv__.predict(x_test) # prediction on test data

svc_classification_report= classification_report(y_test,svc_pred) # classification report
print(svc_classification_report)

svm_conf_matrix= confusion_matrix(y_test,svc_pred) # confusion matrix
sns.heatmap(svm_conf_matrix,annot=True,fmt="0.2f") # ploting the heatmap

"""**Conclusion**
1. Most Traveller type prefer Economy class as their best choice.
2. The bulk of recommendations according to cabin service starts from service
   ratings of 4 for all classes be it Economy, Business, First class or Premium Economy.
3. The best tradeoff between Ground Service and Air Service is given by Nippon
   Airways.
4. Cathy Pacific Airlines has most no of data values in the dataset.
5. Class Imbalance is present in the dataset.
6. Best Classification model is Decision Tree Classification which is giving   accuracy of 94% even without hyperparameter tuning.
7. The 2nd best classification model is Radom Forest Classification with hyperparameter tuning giving accuracy of 93.12 %


"""